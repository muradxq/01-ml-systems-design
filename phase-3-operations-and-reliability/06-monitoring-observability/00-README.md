# üìä Monitoring & Observability

## Overview

Monitoring and observability are critical for ML systems. They enable detection of issues, performance tracking, and system optimization. Unlike traditional software where bugs are introduced by code changes, ML systems can degrade silently due to data drift, concept drift, or model decay‚Äîmaking comprehensive monitoring essential.

---

## üéØ Learning Objectives

After completing this section, you should understand:
- Model monitoring strategies and what metrics to track
- Data drift detection methods and implementation
- Performance metrics for both technical and business perspectives
- Alerting systems design and best practices
- How to build a comprehensive observability stack

---

## üìö Topics Covered

1. [Model Monitoring](./01-model-monitoring.md)
   - What to monitor (predictions, performance, system health)
   - Metrics and KPIs for ML systems
   - Tools and frameworks (Evidently, Fiddler, custom solutions)

2. [Data Drift Detection](./02-data-drift-detection.md)
   - Types of drift (data drift, concept drift, label drift)
   - Statistical detection methods
   - Mitigation strategies and retraining triggers

3. [Performance Metrics](./03-performance-metrics.md)
   - Technical metrics (latency, throughput, error rates)
   - Business metrics (conversion, revenue impact)
   - Tracking and analysis frameworks

4. [Alerting Systems](./04-alerting-systems.md)
   - Alert design principles
   - Thresholds and rules configuration
   - Notification channels and escalation

5. [SLOs, SLIs & Distributed Tracing](./05-slos-distributed-tracing.md)
   - SLI/SLO/SLA definitions for ML systems
   - Error budgets and policies
   - Distributed tracing for ML pipelines
   - On-call playbooks for ML incidents

---

## üèóÔ∏è Monitoring Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ML System in Production                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ   Model     ‚îÇ  ‚îÇ   Feature   ‚îÇ  ‚îÇ    Data     ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ   Serving   ‚îÇ  ‚îÇ   Store     ‚îÇ  ‚îÇ   Pipeline  ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                ‚îÇ                ‚îÇ
          ‚ñº                ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Metrics Collection Layer                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ  Model      ‚îÇ  ‚îÇ  Feature    ‚îÇ  ‚îÇ   Data      ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  Metrics    ‚îÇ  ‚îÇ  Metrics    ‚îÇ  ‚îÇ   Metrics   ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  - Latency  ‚îÇ  ‚îÇ  - Freshness‚îÇ  ‚îÇ  - Volume   ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  - Accuracy ‚îÇ  ‚îÇ  - Coverage ‚îÇ  ‚îÇ  - Quality  ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  - Drift    ‚îÇ  ‚îÇ  - Drift    ‚îÇ  ‚îÇ  - Schema   ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Analysis & Storage Layer                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Time Series Database (Prometheus, InfluxDB, CloudWatch)‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Log Storage (ELK Stack, CloudWatch Logs, Splunk)       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Trace Storage (Jaeger, Zipkin, X-Ray)                  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Visualization & Alerting                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ  Dashboards ‚îÇ  ‚îÇ   Alerts    ‚îÇ  ‚îÇ   Reports   ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  (Grafana)  ‚îÇ  ‚îÇ  (PagerDuty)‚îÇ  ‚îÇ  (Custom)   ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä What to Monitor

### 1. Model Performance Metrics

| Metric Type | Examples | Purpose |
|-------------|----------|---------|
| **Accuracy Metrics** | Precision, Recall, F1, AUC | Track prediction quality |
| **Prediction Distribution** | Mean, variance, percentiles | Detect output drift |
| **Confidence Scores** | Mean confidence, low-confidence rate | Identify uncertainty |
| **Error Analysis** | Error types, patterns | Understand failures |

### 2. System Performance Metrics

| Metric Type | Examples | Purpose |
|-------------|----------|---------|
| **Latency** | p50, p95, p99 response times | User experience |
| **Throughput** | Requests/second, predictions/minute | Capacity planning |
| **Resource Usage** | CPU, Memory, GPU utilization | Cost optimization |
| **Error Rates** | 4xx, 5xx errors, timeouts | System health |

### 3. Data Quality Metrics

| Metric Type | Examples | Purpose |
|-------------|----------|---------|
| **Data Volume** | Records/day, bytes processed | Detect ingestion issues |
| **Schema Health** | Missing fields, type mismatches | Data integrity |
| **Distribution Stats** | Feature means, nulls, outliers | Detect data drift |
| **Freshness** | Data age, update frequency | Staleness detection |

### 4. Business Metrics

| Metric Type | Examples | Purpose |
|-------------|----------|---------|
| **Engagement** | CTR, conversions, user actions | Business impact |
| **Revenue** | Revenue per prediction, lift | Financial impact |
| **User Feedback** | Ratings, complaints, corrections | Quality signal |

---

## üõ†Ô∏è Monitoring Stack Options

### Option 1: Cloud-Native Stack

```
AWS CloudWatch / GCP Cloud Monitoring / Azure Monitor
‚îú‚îÄ‚îÄ Metrics Collection
‚îú‚îÄ‚îÄ Log Aggregation
‚îú‚îÄ‚îÄ Alerting
‚îî‚îÄ‚îÄ Dashboards
```

**Pros:** Easy setup, integrated with cloud services
**Cons:** Vendor lock-in, can be expensive at scale

### Option 2: Open Source Stack

```
Prometheus + Grafana + ELK
‚îú‚îÄ‚îÄ Prometheus (Metrics)
‚îú‚îÄ‚îÄ Elasticsearch (Logs)
‚îú‚îÄ‚îÄ Jaeger (Traces)
‚îî‚îÄ‚îÄ Grafana (Visualization)
```

**Pros:** Flexible, cost-effective, no vendor lock-in
**Cons:** More setup and maintenance required

### Option 3: ML-Specific Tools

```
Evidently AI / Fiddler / Arize
‚îú‚îÄ‚îÄ Model Performance Monitoring
‚îú‚îÄ‚îÄ Data Drift Detection
‚îú‚îÄ‚îÄ Feature Monitoring
‚îî‚îÄ‚îÄ Explainability
```

**Pros:** ML-specific features, easy drift detection
**Cons:** Additional tool to manage, cost

---

## üìù Implementation Example

### Setting Up Basic Monitoring

```python
import prometheus_client as prom
from functools import wraps
import time

# Define metrics
prediction_latency = prom.Histogram(
    'model_prediction_latency_seconds',
    'Time spent processing prediction',
    buckets=[.01, .025, .05, .075, .1, .25, .5, .75, 1.0]
)

prediction_counter = prom.Counter(
    'model_predictions_total',
    'Total number of predictions',
    ['model_version', 'prediction_class']
)

prediction_confidence = prom.Histogram(
    'model_prediction_confidence',
    'Distribution of prediction confidence scores',
    buckets=[.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0]
)

# Decorator for monitoring predictions
def monitor_prediction(model_version):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            # Make prediction
            result = func(*args, **kwargs)
            
            # Record metrics
            latency = time.time() - start_time
            prediction_latency.observe(latency)
            prediction_counter.labels(
                model_version=model_version,
                prediction_class=result['class']
            ).inc()
            prediction_confidence.observe(result['confidence'])
            
            return result
        return wrapper
    return decorator

# Usage
@monitor_prediction(model_version="v1.2.3")
def predict(features):
    prediction = model.predict(features)
    return {
        'class': prediction.argmax(),
        'confidence': prediction.max()
    }
```

### Data Drift Monitoring

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset
import pandas as pd

def monitor_data_drift(reference_data: pd.DataFrame, 
                       current_data: pd.DataFrame) -> dict:
    """
    Monitor data drift between reference and current data.
    
    Args:
        reference_data: Historical/training data
        current_data: Recent production data
        
    Returns:
        Drift report with metrics
    """
    report = Report(metrics=[DataDriftPreset()])
    report.run(reference_data=reference_data, current_data=current_data)
    
    # Extract drift metrics
    drift_results = report.as_dict()
    
    # Check for significant drift
    drift_detected = drift_results['metrics'][0]['result']['dataset_drift']
    drifted_features = [
        feature for feature, data in 
        drift_results['metrics'][0]['result']['drift_by_columns'].items()
        if data['drift_detected']
    ]
    
    return {
        'drift_detected': drift_detected,
        'drifted_features': drifted_features,
        'drift_share': len(drifted_features) / len(reference_data.columns)
    }
```

---

## üîë Key Principles

1. **Monitor Everything**: Models, data, features, and infrastructure
2. **Track Trends**: Historical analysis reveals gradual degradation
3. **Alert Appropriately**: Meaningful alerts with proper thresholds
4. **Automate Responses**: Auto-retrain, auto-rollback when possible
5. **Continuous Improvement**: Learn from monitoring data to improve systems
6. **Context Matters**: Correlate ML metrics with business outcomes
7. **Baseline First**: Establish baselines before setting alert thresholds

---

## ‚ö†Ô∏è Common Pitfalls

| Pitfall | Problem | Solution |
|---------|---------|----------|
| **Alert Fatigue** | Too many alerts, team ignores them | Tune thresholds, prioritize alerts |
| **Missing Ground Truth** | Can't measure accuracy in production | Use proxy metrics, delayed labels |
| **Monitoring Blind Spots** | Only monitor model, not data | Monitor entire pipeline |
| **No Historical Context** | Can't compare to past performance | Store and compare metrics over time |
| **Siloed Metrics** | ML metrics separate from business | Correlate ML and business metrics |

---

## üöÄ Next Steps

- Learn about [Model Monitoring](./01-model-monitoring.md) - deep dive into model-specific monitoring
- Understand [Data Drift Detection](./02-data-drift-detection.md) - detect and handle drift
- Explore [Performance Metrics](./03-performance-metrics.md) - technical and business metrics
- Study [Alerting Systems](./04-alerting-systems.md) - build effective alerting

Then proceed to [Scalability & Performance](../07-scalability-performance/00-README.md) to learn how to scale your monitored systems.
